*/3 * * * * /usr/local/nrdp/clients/nrds/nrds.pl -H 'controller.hamilton' > /dev/null 2>&1
git config http.sslVerify false (nextgen2)
/usr/local/nagios/libexec/check_inlettemp: line 34: cd: /var/spool/nagios/ipmi-check: No such file or directory


Nagios - Cluster and Host Monitoring Configuration
--------------------------------------------------

Contents
--------

1. Add a Cluster to Monitoring.............................................................................................................
1.1. Create a New Host Group Object Definition.............................................................................................
1.2. Create a New Host Object Definition...................................................................................................
1.3. Update Nagios Service Main Configuration..............................................................................................
1.4. Install NRDS Clients on Machines to be Monitored......................................................................................
2. Adding a Host to Monitoring..........................................................................................................
2.1. Adding a Host to Monitoring - Server Side Configuration.............................................................................
2.2. Adding a Host to Monitoring - Client Side Configuration.............................................................................
3. Adding Service Checks to Hosts..........................................................................................................
3.1. Adding Service Checks to Hosts - Server Side Configuration............................................................................
3.2. Adding Service Checks to Hosts - Client Side Configuration............................................................................
4. Addiing Hardware Service Checks to Hosts................................................................................................
5. Troubleshooting.........................................................................................................................

-----------------------------------------------------------------------------------------------------------------------------------------------------------------
Notes:
-----------------------------------------------------------------------------------------------------------------------------------------------------------------
text enclosed in angular brackets, refers to parameters that are specific to the use case. e.g. Where <cluster> appears in the document, replace with a cluster name of interest, e.g.
laplace or hamilton.

Generally, configuration must be performed on client and server. Server configuration, is used by Nagios to process and display information it receives from clients correctly. Client configuration, species what checks to run and where to transfer the data.
-----------------------------------------------------------------------------------------------------------------------------------------------------------------

1. Add a Cluster to Monitoring
------------------------------

In this section, a new 'Host Group' is created and assigned a Controller as its initial host member. Initially, this host will not have any services checked. Instead only the state of the host (UP or DOWN), will be monitored.

1.1. Create a New Host Group Object Definition
----------------------------------------------

Host Group objects are used to represent clusters in Nagios.

1. Log in as root, to flightcenter-nagios2

2. Create a directory to store the object definitions specific to a cluster.

    # mkdir /usr/local/nagios/etc/objects/<cluster>

3. Set the ownership of the directory:

    # chown -R nagios:nagios /usr/local/nagios/etc/objects/<cluster>

4. Create a new config file named <cluster>-hostgroup.cfg, by copying the generic-cluster hostgroup object definition file:

    # cp /usr/local/nagios/etc/objects/generic-cluster/CLUSTER-hostgroup.cfg /usr/local/nagios/etc/objects/<cluster>/<cluster>-hostgroup.cfg
    
5. Replace the <cluster> placeholders in the new file with suitable values:

    # sed -i 's/CLUSTER/<cluster>/g' <cluster>-hostgroup.cfg
    
Example: Replace placeholders in a new Cluster's hostgroup object definition file with the cluster's details:

    # sed -i 's/CLUSTER/<cluster>/g' hamilton-hostgroup.cfg

1.2. Create a Host Object Definition for the Controller
-------------------------------------------------------

The controller will be the initial member of the host group.

1. Create a directory to store the host object definitions:

    # mkdir /usr/local/nagios/etc/objects/<cluster>/hosts
    # cd /usr/local/nagios/etc/objects/<cluster>/hosts
    
2. Copy the generic-cluster's controller host definition file:

    # cp /usr/local/nagios/etc/objects/generic-cluster/hosts/controller.pri.CLUSTER.cfg /usr/local/nagios/etc/objects/<cluster>/hosts/controller.pri.<cluster>

3. Replace the placeholders for the new controller object's details:
    
    # sed -i 's/CLUSTER/<cluster>/g' /usr/local/nagios/etc/objects/<cluster>/hosts/controller.pri.<cluster>

1.3 Update Nagios Service Configuration
---------------------------------------

1. Open the main Nagios config file:

    # vi /usr/local/nagios/etc/nagios.cfg

2. Insert the following lines to the config file, beneath the text: # Alces Object Definitions

cfg_dir=/usr/local/nagios/etc/objects/<cluster>

3. Run a sanity check on the syntax and structure of the updated configuration:

     # /usr/local/nagios/bin/nagios -v /usr/local/nagios/etc/nagios.cfg

The new object definitions should be found and no errors should be present. Correct any that arise before attempting to restart Nagios.

5. Restart Nagios:

    # systemctl restart nagios && tail -f /usr/local/nagios/var/nagios.log

Note: && tail -f /usr/local/nagios/var/nagios.login is OPTIONAL and is useful to check the Nagios log file to verify processing.

6. Check the web UI on https://flightcenter-nagios2/nagios and navigate to Host Groups in the menu pane to the left of the screen. You will notice, that there is now a new Host Group named <cluster> with a single host named controller. At this point data for this host will be pending as no checks will have been run on the controller.

The next stage is to install the NRDP client on to the controller, so that passive checks will be performed and sent to the NRDP Server: flightcenter-nagios2


1.4. Install NRDS Clients on Machines to be Monitored
-----------------------------------------------------

1. SSH to the controller of the cluster that will be monitored by flightcenter-nagios2.
    
2. Download NRDP Client Installation files:

The following script is will be downloaded onto the machine, obtain the machine's profile type from its hostname, then pull down the appropriate branch from git. It then removes the downloaded git repoistory.

    # curl https://raw.githubusercontent.com/alces-software/nagios/master/cl_installnrds.sh | /bin/bash
    
Installation of the Client side checks is now complete. Pay attention over the next few minutes to the Nagios Web UI/Slack for updated messages.


2. Adding a Host to Monitoring
-------------------------------

Preconditions:
1. Complete (The cluster a node is a member of must have already been added to monitoring).

2.1 Adding a Host to Monitoring - Server Side Configuration
-----------------------------------------------------------

1. Login to flightcenter-nagios2 as root

2. Run the following command:

    #  ./sv_add-host-to-hostgroup.sh <short hostname>.pri.<cluster>
    
6. Run a sanity check on the Nagios Configuration to ensure the syntax and structure is valid:

    # /usr/local/nagios/bin/nagios -v /usr/local/nagios/etc/nagios.cfg
    
7. Restart the Nagios Service:

    # systemctl restart nagios && tail -f /usr/local/nagios/var/nagios.log
    
Login to the Nagios UI on https://flightcenter-nagios2.alces-flight.com/nagios and confirm that the new host is visible under the 'Host Groups' section on the navigation menu.
    
You will then be able to see the new Host in the UI, under the list of hosts, with its hostname shown and a status of PENDING.


2.2 Adding a Host to a Cluster - Client Side Configuration
----------------------------------------------------------

1. Log in to controller of the cluster, that the new host to be monitored is a member of:


2. Run the following command:

pdsh -w <short_hostname> 'curl https://raw.githubusercontent.com/alces-software/nagios/master/cl_installnrds.sh | /bin/bash'

****************************************************************************************************************************************************
Example: Remotely executing the install script on a cluster member (the slurmaster) via the controller.
****************************************************************************************************************************************************
[root@controller [nextgen2] ~]# pdsh -w infra02 'curl https://raw.githubusercontent.com/alces-software/nagios/master/cl_installnrds.sh | /bin/bash'
****************************************************************************************************************************************************

pdsh -w node[917-921] 'curl https://raw.githubusercontent.com/alces-software/nagios/master/cl_installnrds.sh | /bin/bash


2.3. Adding Multiple Hosts to a Cluster - Client Side Configuration
-------------------------------------------------------------------

1. Obtain a list of the hosts to be added for monitoring. You can do this by logging in to the controller of the cluster that has hosts to be monitored.
Then, run the command:

    # nodeattr -n <gender>
    
Example: Obtaining a list of nodes and adding two nodes at once to Nagios Server Configuration

[root@controller [nextgen2] ~]# nodeattr -n all
admin01
admin02
infra01
infra02
login1
login2
master1
node01
.
.
.

Two nodes to be added: admin01 and admin02:, 

2. Copy the names of the nodes to be added to a new file on the Nagios Server:

    # cd /usr/local/nagios/etc/objects
    
    # vi newhosts.txt
    
    Paste the nodes in to the newhosts.txt file, then save and close the file.
    
3. Run the following script:

    # ./sv_add-hosts-to-hostgroup.sh <name of file> <cluster>
    
    The existence of the config files which contain host definitions for these hosts can be verified by navigating to:
    
    # cd /usr/local/nagios/etc/objects/<cluster>/hosts
    # ls -l
    
    See that the new files are present. 
    
4. Run a syntax check on the Nagios config file:

    # /usr/local/nagios/bin/nagios -v /usr/local/nagios/etc/nagios.cfg
    
5. Restart nagios:

    # systemctl restart nagios && tail -f /usr/local/nagios/var/nagios.log


2.2 Adding Multiple Hosts to a Cluster - Client Side Configuration
-------------------------------------------------------------------

1. Log in to controller of the cluster, that the new host to be monitored is a member of:

2. Run the following command:

pdsh <command to add multiple hosts> 'curl https://raw.githubusercontent.com/alces-software/nagios/master/cl_installnrds.sh | /bin/bash'

Example: Add the two hosts: 'admin01' and 'admin02' on the nextgen2 cluster



4. Adding Hardware Service Checks to Hosts
------------------------------------------


4.1. Install and Configure Hardware Check dependencies - Client Side Configuration
-----------------------------------------------------------------------------------------

Hardware checks work the same as software checks, however they have dependencies on third party applications that obtain information about the hardware.

ipmi-tool
---------

The ipmi-tool is used to query nodes for various hardware properties. Currently we use this to monitor CPU core temperature and ECC memory information.

4.2.1. Check if ipmi-tool is installed
--------------------------------------

You can query the local machines yum database, to see whether the package is already installed:

    # yum info freeipmi
    
    
Installed Packages
Name        : freeipmi
Arch        : x86_64
Version     : 1.5.7
Release     : 2.el7
Size        : 9.9 M
Repo        : installed
From repo   : base

    As above, if already installed, the metadata of the package should show that it is a) "Repo : installed" and b) "From Repo : base. You can skip to step 4.2.4.

4.2.2. Install ipmi-tool
------------------------

On some machines, the epel yum repository is installed. The ipmi tool should be installed from the centos-7-base repository and NOT the epel repository.

    # yum --disablerepo epel install freeipmi

If yum  returns with an error and the output is: EPEL is not found, run the following:

    # yum -y install freeipmi
    
4.2.3. Add authentication details to freeipmi
---------------------------------------------
    
Modify the freeipmi config and set the username and password. 

    # vi /etc/freeipmi/freeipmi.conf
    
Add the two lines:

    username admin
    
    below the # username myusername sample entry (commented out)
    
    password <password>
    
    below the # password mypassword sample entry (commented out)
    

4.2.4. Add the script to retrieve IPMI sensor output
----------------------------------------------------

Place the script named: alces-impi-check into the /etc/cron.hourly. This script runs with root permissions. The directories it creates are owned by nagios, however the files that are written to them via the ipmi tools (sensors and sel), are owned by root. Nagios does have read permissions, so this should pose no problems in terms of accessing the data for passive checks.

# cd /etc/cron.hourly

This script should be present on the CONTROLLER:

#!/bin/bash
# script to retrieve IPMI sensors output

export PATH=/opt/metalware/opt/pdsh/bin:/opt/metalware/opt/genders/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin

[[ ! -x /opt/metalware/opt/genders/bin/nodeattr ]] && exit 0
[[ ! -d /var/spool/nagios/ipmi-check ]] && mkdir -p /var/spool/nagios/ipmi-check && chown -R nagios /var/spool/nagios/ipmi-check
[[ ! -d /var/spool/nagios/ecc-check ]] && mkdir -p /var/spool/nagios/ecc-check && chown -R nagios /var/spool/nagios/ecc-check

. /etc/profile

for node in `nodeattr -s compute` `nodeattr -s storage` master1 master2
do
   ipmi-sensors -f -D LAN_2_0 -h $node.bmc > /dev/null 2>&1
   ipmi-sensors -D LAN_2_0 -h $node.bmc > /var/spool/nagios/ipmi-check/$node.ipmi.out 2>&1
   ipmi-sel -D LAN_2_0 -h $node.bmc 2> /dev/null > /var/spool/nagios/ecc-check/$node.ecc.out 2>&1

done

# remove files for login nodes
rm -f /var/spool/nagios/ecc-check/login* /var/spool/nagios/ipmi-check/login*

4.2.2 Verify The Script Runs Correctly
--------------------------------------

# ./alces-ipmi-check

Check that: 
1) /var/spool/nagios/ecc-check appears and contains files: <host>.ecc.out and each of these files has correct content.
2) /var/spool/nagios/ipmi-check appears and contains files <host>.ipmi.out and each of these files has the correct content.

Storage Checks
--------------

Before running the Nagios check under cron, find the commands that are dependencies and ensure they run OK.

Example:

We want to Check the System Disk (Check systemdisk) on master1.pri.laplace.

1. Open the config file /usr/local/nrdp/clients/nrds/nrds.cfg

note the following line entry:

command[Check systemdisk]=/usr/local/nagios/libexec/check_PERC_H7X0 0 0

open the script check_PERC_H7X0 and find the commands it runs. In this case we see that:

sudo /opt/MegaRAID/MegaCli/MegaCli64 -ldinfo -l $vol -A $card 

2. Run, as root the command: 

    # /opt/MegaRAID/MegaCli/MegaCli64 -ldinfo -l 0 -A 0 | grep -i "State"
    
    We should see state as Optimal.
    
Note that this command also uses sudo. To use sudo, the nagios user will need to be given permission to do so.

3. Grant permission for Nagios to run commands as sudo.

    # visudo

Add the following to the Command Aliases section, labelled: ## Command Aliases

    Cmnd_Alias MONITOR = /opt/MegaRAID/MegaCli/MegaCli64 -ldinfo *, /usr/sbin/crm_mon -s, /usr/sbin/multipath -ll, /usr/bin/ipmitool sensor, /usr/bin/SMcli -d -v, /usr/bin/ipmitool sel elist

Then append the following to the (bottom) of the file:

    nagios    ALL=(ALL)       NOPASSWD: MONITOR

Save and close the file.

PSU Checks
----------

5. Troubleshooting
------------------

Useful information can be found from the following:

/usr/local/nagios/var/nagios.log (To check the server side Nagios log file)
/var/log/cron (To check the client side cron log to ensure that the scheduled task is being run)
crontab -u nagios -l ; verify that the cron job is present in the nagios user's cron file

Sending Custom Messages to NRDP Server/Nagios Server/flightcenter-nagios2
-------------------------------------------------------------------------

On each client, there is a script named: send_nrdp.sh

This is the script that is actually used (by the Perl script run under cron), to send data to the flightcenter-nagios2.

It is useful to use this to send custom commands to the server, e.g. for simulating issues.

e.g. 

Required:
    -u,    URL of NRDP server.  Usually http://<IP_ADDRESS>/nrdp/
    -t,    Shared token.  Must be the same token set in NRDP Server

Options:
    Single Check:
        -H    host name
        -s    service name
        -S    State
        -o     output


./send_nrdp.sh -u http://10.78.0.30/nrdp -t RrpjfuGiOOb5 -H controller.pri.csf3 -s "Check Load" -S1 -o "Premigration test!"
./send_nrdp.sh -u http://10.78.0.31/nrdp -t 90t3s7t0k3n90 -H controller.pri.csf3 -s "Check Load" -S1 -o "Premigration test!

This will force the Check Load service monitor in to a HARD WARNING state. Recovery (OK), will lead it back in to a HARD OK state.

./send_nrdp.sh -u https://10.78.0.31/nrdp -t 90t3s7t0k3n90 -H controller.pri.csf3 -s "Check Load" -S 2 -o "Testing a Critical"

If the service is resumed, the status will transition immediately to HARD OK.

</WIP>


Error Message: /usr/local/nagios/libexec/check_inlettemp: line 34: cd: /var/spool/nagios/ipmi-check: No such file or directory
-------------------------------------------------------------------------------------------------------------------------------

This requires installation of alces-ipmi-tool.

Where is the alces-ipmi-tool located ?
What user does it run under ?

Controller's need:

/var/spool/nagios/ipmi-check and /var/spool/nagios/ecc-check




